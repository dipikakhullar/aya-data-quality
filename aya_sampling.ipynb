{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cb8833d-83db-407b-8bc4-a6960df36eea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7803fcb-ac52-49b3-a859-9b59d4b2c1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache redirected to larger volume.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/home/ec2-user/SageMaker/huggingface_cache\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/home/ec2-user/SageMaker/huggingface_cache\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/home/ec2-user/SageMaker/huggingface_cache\"\n",
    "print(\"Cache redirected to larger volume.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0c75554-9c62-4aba-b784-6db84afe8088",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['translated_wikiqa_train_sample.json',\n",
       " 'translated_cnn_dailymail_train_sample.json',\n",
       " 'translated_nqopen_train_sample.json',\n",
       " 'translated_flan_qa_train_sample.json',\n",
       " 'translated_flan_lambada_train_sample.json',\n",
       " 'translated_xlel_wd_train_sample.json',\n",
       " 'translated_wiki_split_train_sample.json',\n",
       " 'translated_joke_explaination_train_sample.json',\n",
       " 'translated_adversarial_qa_train_sample.json',\n",
       " 'translated_dolly_train_sample.json',\n",
       " 'translated_hotpotqa_train_sample.json',\n",
       " 'translated_flan_coqa_train_sample.json',\n",
       " 'translated_paws_train_sample.json',\n",
       " 'translated_flan_gem_wiki_train_sample.json',\n",
       " 'translated_mintaka_train_sample.json',\n",
       " 'translated_soda_train_sample.json',\n",
       " 'translated_flan_cot_train_sample.json',\n",
       " 'translated_piqa_train_sample.json']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"translated_subsets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffb5aef1-22c6-48c8-8c1f-2d59b1cf6890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['translated_adversarial_qa',\n",
       " 'translated_cnn_dailymail',\n",
       " 'translated_dolly',\n",
       " 'translated_flan_coqa',\n",
       " 'translated_flan_cot',\n",
       " 'translated_flan_gem_wiki',\n",
       " 'translated_flan_lambada',\n",
       " 'translated_flan_qa',\n",
       " 'translated_hotpotqa',\n",
       " 'translated_joke_explaination',\n",
       " 'translated_mintaka',\n",
       " 'translated_mlqa',\n",
       " 'translated_nqopen',\n",
       " 'translated_paws',\n",
       " 'translated_piqa',\n",
       " 'translated_soda',\n",
       " 'translated_wiki_split',\n",
       " 'translated_wikiqa',\n",
       " 'translated_xlel_wd']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e505fc0b-cb6e-40aa-be2a-de293284ba31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_subset_names = ['aya_dataset', 'templated_afriqa', 'templated_afrisenti', 'templated_amharic_qa', 'templated_armenian_instruct', 'templated_bengali_news', 'templated_dutch_imdb', 'templated_hindi_headline', 'templated_hindi_news', 'templated_indic_paraphrase', 'templated_indic_sentiment', 'templated_indo_stories', 'templated_japanese_instruct', 'templated_joke_explaination', 'templated_ligurian_news', 'templated_masakhanews', 'templated_mintaka', 'templated_ntx_llm', 'templated_nusax_senti', 'templated_persian_farstail', 'templated_persian_instruct', 'templated_scirepeval', 'templated_seed_instruct', 'templated_soda', 'templated_tamil_stories', 'templated_tamil_thirukkural', 'templated_telugu_food', 'templated_telugu_jokes', 'templated_telugu_news', 'templated_telugu_poems', 'templated_telugu_riddles', 'templated_thai_pos', 'templated_thai_scb', 'templated_thai_usembassy', 'templated_thai_wikitionary', 'templated_turku_paraphrase', 'templated_ukranian_gec', 'templated_uner_llm', 'templated_urdu_news_category', 'templated_urdu_news_gen', 'templated_urdu_news_headline', 'templated_wiki_split', 'templated_xcsqa', 'templated_xlel_wd', 'templated_xwikis', 'translated_adversarial_qa', 'translated_cnn_dailymail', 'translated_dolly', 'translated_flan_coqa', 'translated_flan_cot', 'translated_flan_gem_wiki', 'translated_flan_lambada', 'translated_flan_qa', 'translated_hotpotqa', 'translated_joke_explaination', 'translated_mintaka', 'translated_mlqa', 'translated_nqopen', 'translated_paws', 'translated_piqa', 'translated_soda', 'translated_wiki_split', 'translated_wikiqa', 'translated_xlel_wd']\n",
    "templated_subsets = [s for s in all_subset_names if \"templated\" in s]\n",
    "translated_subsets = [s for s in all_subset_names if \"translated\" in s]\n",
    "aya_subset = [\"aya_dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d27d53-c746-4e6e-b9c9-d1bdd7e6def3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 44, 19, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_subset_names), len(templated_subsets), len(translated_subsets), len(aya_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c8d14-ca12-4e60-adfd-3b02ecb9ef04",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sampling Code\n",
    "Note: We will use the following num_samples for each subset to get a stratified sample by subset name for each partition (aya, templated, translated)\n",
    "```\n",
    "templated_subsets --> 114 (44 subsets, we want a 5k sample 5000/44)\n",
    "translated_subsets --> 264 (19 subsets, we want a 5k sample 5000/19)\n",
    "aya_subset --> 5000 (1 subsets, we want a 5k sample 5000/1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41c3e888-1dba-42bb-b027-36891aba635e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing subset: translated_mlqa\n",
      "Successfully sampled 264 entries from translated_mlqa\n",
      "Saved to: translated_subsets/translated_mlqa_val_sample.json\n",
      "\n",
      "All subsets processed.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import gc  # For explicit garbage collection\n",
    "\n",
    "def sample_from_dataset(subset_name, output_dir, num_samples=264):\n",
    "    \"\"\"\n",
    "    Sample from a single dataset subset and save to disk.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing subset: {subset_name}\")\n",
    "    output_path = os.path.join(output_dir, f\"{subset_name}_train_sample.json\")\n",
    "    \n",
    "    try:\n",
    "        # Load only the train split\n",
    "        dataset = load_dataset(\"CohereForAI/aya_collection\", subset_name, split=\"validation\", download_mode=\"reuse_dataset_if_exists\")  # Select only the first `num_samples` rows\n",
    "\n",
    "        \n",
    "        # Calculate indices for sampling\n",
    "        total_size = len(dataset)\n",
    "        if total_size < num_samples:\n",
    "            print(f\"Dataset has fewer than {num_samples} rows; sampling all {total_size} rows.\")\n",
    "            indices = range(total_size)\n",
    "        else:\n",
    "            # Set the random seed\n",
    "            random.seed(seed)\n",
    "            indices = random.sample(range(total_size), num_samples)\n",
    "        \n",
    "        # Sample using indices\n",
    "        sampled_data = [dataset[idx] for idx in indices]\n",
    "        \n",
    "        # Save to disk\n",
    "        with open(output_path, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(sampled_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"Successfully sampled {len(sampled_data)} entries from {subset_name}\")\n",
    "        print(f\"Saved to: {output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {subset_name}: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        # Explicit cleanup\n",
    "        if 'dataset' in locals():\n",
    "            del dataset\n",
    "        if 'sampled_data' in locals():\n",
    "            del sampled_data\n",
    "        gc.collect()  # Force garbage collection\n",
    "        \n",
    "# Create output directory\n",
    "output_dir = \"templated_subsets\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for subset_name in templated_subsets:\n",
    "    sample_from_dataset(subset_name, output_dir, num_samples=114)\n",
    "\n",
    "print(\"\\nAll subsets processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e210c9-6cf4-4a30-a1fa-01b037283764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Directory containing the sampled JSON files\n",
    "input_dir = \"templated_subsets\"\n",
    "\n",
    "# List to store data from all JSONs\n",
    "all_data = []\n",
    "\n",
    "# Iterate through all JSON files in the directory\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        subset_name = file_name.rsplit(\".\", 1)[0]  # Get the file name without the extension\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        \n",
    "        # Load the JSON file\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Add a column for subset_name\n",
    "        for entry in data:\n",
    "            entry[\"subset_name\"] = subset_name\n",
    "        \n",
    "        # Append to the all_data list\n",
    "        all_data.extend(data)\n",
    "\n",
    "# Create a pandas DataFrame from the combined data\n",
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "926624f9-4c6d-482d-888e-ae24759b4597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully saved to translated_sample_5k.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a Parquet file without the index\n",
    "output_file = \"templated_sample_5k.parquet\"\n",
    "df.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"DataFrame successfully saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4539ccd-b931-48fd-82a1-03caa08474e7",
   "metadata": {},
   "source": [
    "### Concatenating Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a76fc57b-6404-411e-b187-fb8db56882fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "templated_file = \"aya-data-quality/templated_sample_5k.parquet\"\n",
    "translated_file = \"aya-data-quality/translated_sample_5k.parquet\"\n",
    "aya_file = \"aya-data-quality/aya_sample_5k.parquet\"\n",
    "\n",
    "# Load datasets\n",
    "templated_df = pd.read_parquet(templated_file)\n",
    "translated_df = pd.read_parquet(translated_file)\n",
    "aya_df = pd.read_parquet(aya_file)\n",
    "\n",
    "# Add 'aya_partition' column\n",
    "templated_df[\"aya_partition\"] = \"templated\"\n",
    "translated_df[\"aya_partition\"] = \"translated\"\n",
    "aya_df[\"aya_partition\"] = \"aya\"\n",
    "\n",
    "# Concatenate datasets\n",
    "combined_df = pd.concat([templated_df, translated_df, aya_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94593fa5-30ce-4655-9e1e-7234d1d03316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>inputs</th>\n",
       "      <th>targets</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sub_dataset_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>template_id</th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>script</th>\n",
       "      <th>subset_name</th>\n",
       "      <th>aya_partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303</td>\n",
       "      <td>Quæ a l’é a traduçion italiaña de sto testo?\\n...</td>\n",
       "      <td>A traduçion in italian do testo a l’é:\\nSalari...</td>\n",
       "      <td>Lijnews-instruct</td>\n",
       "      <td>lijnews-instruct-lij-ita</td>\n",
       "      <td>translation</td>\n",
       "      <td>18</td>\n",
       "      <td>lij</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "      <td>templated_ligurian_news_train_sample</td>\n",
       "      <td>templated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212</td>\n",
       "      <td>Traduci questo testo in genovese:\\nL'Europa ap...</td>\n",
       "      <td>La traduzione in genovese del testo è:\\nL'Eurö...</td>\n",
       "      <td>Lijnews-instruct</td>\n",
       "      <td>lijnews-instruct-ita-lij</td>\n",
       "      <td>translation</td>\n",
       "      <td>6</td>\n",
       "      <td>ita</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "      <td>templated_ligurian_news_train_sample</td>\n",
       "      <td>templated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170</td>\n",
       "      <td>Qual è la traduzione genovese di questo testo?...</td>\n",
       "      <td>La traduzione in genovese del testo è:\\nAttent...</td>\n",
       "      <td>Lijnews-instruct</td>\n",
       "      <td>lijnews-instruct-ita-lij</td>\n",
       "      <td>translation</td>\n",
       "      <td>8</td>\n",
       "      <td>ita</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "      <td>templated_ligurian_news_train_sample</td>\n",
       "      <td>templated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290</td>\n",
       "      <td>Traduxi in lengua italiaña:\\nPapê fäsci in scî...</td>\n",
       "      <td>A traduçion in italian do testo a l’é:\\nFalsi ...</td>\n",
       "      <td>Lijnews-instruct</td>\n",
       "      <td>lijnews-instruct-lij-ita</td>\n",
       "      <td>translation</td>\n",
       "      <td>14</td>\n",
       "      <td>lij</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "      <td>templated_ligurian_news_train_sample</td>\n",
       "      <td>templated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>331</td>\n",
       "      <td>Quæ a l’é a traduçion italiaña de sto testo?\\n...</td>\n",
       "      <td>A traduçion in italian do testo a l’é:\\nRussia...</td>\n",
       "      <td>Lijnews-instruct</td>\n",
       "      <td>lijnews-instruct-lij-ita</td>\n",
       "      <td>translation</td>\n",
       "      <td>18</td>\n",
       "      <td>lij</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "      <td>templated_ligurian_news_train_sample</td>\n",
       "      <td>templated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>151002</td>\n",
       "      <td>Ba mhaith liom tuirse a thabhairt do ghaolta a...</td>\n",
       "      <td>Ba mhaith liom a mholadh dóibh pictiúr greannm...</td>\n",
       "      <td>Aya-Dataset</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>gle</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "      <td>aya_dataset_train_sample</td>\n",
       "      <td>aya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>158437</td>\n",
       "      <td>Ερώτηση: Τι είναι η απάντηση στην αξία της ανά...</td>\n",
       "      <td>Απάντηση: Η ανάγνωση βιβλίων έχει αξία στην εκ...</td>\n",
       "      <td>Aya-Dataset</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ita</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "      <td>aya_dataset_train_sample</td>\n",
       "      <td>aya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15073</th>\n",
       "      <td>65556</td>\n",
       "      <td>Haddii aan haysto 5 moos oo aan 2 xabo siiyo q...</td>\n",
       "      <td>Waxaad haysataa 3 moos.</td>\n",
       "      <td>Aya-Dataset</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>som</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "      <td>aya_dataset_train_sample</td>\n",
       "      <td>aya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15074</th>\n",
       "      <td>122083</td>\n",
       "      <td>Quelle est la capitale du Canada?</td>\n",
       "      <td>La capitale du Canada est Ottawa dans la provi...</td>\n",
       "      <td>Aya-Dataset</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>fra</td>\n",
       "      <td>train</td>\n",
       "      <td>Latn</td>\n",
       "      <td>aya_dataset_train_sample</td>\n",
       "      <td>aya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15075</th>\n",
       "      <td>83691</td>\n",
       "      <td>సహదేవుడెట్టి వాడు ?</td>\n",
       "      <td>సహదేవుడు పాండురాజుకు, మాద్రికి పుట్టిన సంతానం....</td>\n",
       "      <td>Aya-Dataset</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>tel</td>\n",
       "      <td>train</td>\n",
       "      <td>Telu</td>\n",
       "      <td>aya_dataset_train_sample</td>\n",
       "      <td>aya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15076 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             inputs  \\\n",
       "0         303  Quæ a l’é a traduçion italiaña de sto testo?\\n...   \n",
       "1         212  Traduci questo testo in genovese:\\nL'Europa ap...   \n",
       "2         170  Qual è la traduzione genovese di questo testo?...   \n",
       "3         290  Traduxi in lengua italiaña:\\nPapê fäsci in scî...   \n",
       "4         331  Quæ a l’é a traduçion italiaña de sto testo?\\n...   \n",
       "...       ...                                                ...   \n",
       "15071  151002  Ba mhaith liom tuirse a thabhairt do ghaolta a...   \n",
       "15072  158437  Ερώτηση: Τι είναι η απάντηση στην αξία της ανά...   \n",
       "15073   65556  Haddii aan haysto 5 moos oo aan 2 xabo siiyo q...   \n",
       "15074  122083                  Quelle est la capitale du Canada?   \n",
       "15075   83691                                సహదేవుడెట్టి వాడు ?   \n",
       "\n",
       "                                                 targets      dataset_name  \\\n",
       "0      A traduçion in italian do testo a l’é:\\nSalari...  Lijnews-instruct   \n",
       "1      La traduzione in genovese del testo è:\\nL'Eurö...  Lijnews-instruct   \n",
       "2      La traduzione in genovese del testo è:\\nAttent...  Lijnews-instruct   \n",
       "3      A traduçion in italian do testo a l’é:\\nFalsi ...  Lijnews-instruct   \n",
       "4      A traduçion in italian do testo a l’é:\\nRussia...  Lijnews-instruct   \n",
       "...                                                  ...               ...   \n",
       "15071  Ba mhaith liom a mholadh dóibh pictiúr greannm...       Aya-Dataset   \n",
       "15072  Απάντηση: Η ανάγνωση βιβλίων έχει αξία στην εκ...       Aya-Dataset   \n",
       "15073                            Waxaad haysataa 3 moos.       Aya-Dataset   \n",
       "15074  La capitale du Canada est Ottawa dans la provi...       Aya-Dataset   \n",
       "15075  సహదేవుడు పాండురాజుకు, మాద్రికి పుట్టిన సంతానం....       Aya-Dataset   \n",
       "\n",
       "               sub_dataset_name    task_type  template_id language  split  \\\n",
       "0      lijnews-instruct-lij-ita  translation           18      lij  train   \n",
       "1      lijnews-instruct-ita-lij  translation            6      ita  train   \n",
       "2      lijnews-instruct-ita-lij  translation            8      ita  train   \n",
       "3      lijnews-instruct-lij-ita  translation           14      lij  train   \n",
       "4      lijnews-instruct-lij-ita  translation           18      lij  train   \n",
       "...                         ...          ...          ...      ...    ...   \n",
       "15071                         -            -            0      gle  train   \n",
       "15072                         -            -            0      ita  train   \n",
       "15073                         -            -            0      som  train   \n",
       "15074                         -            -            0      fra  train   \n",
       "15075                         -            -            0      tel  train   \n",
       "\n",
       "      script                           subset_name aya_partition  \n",
       "0       Latn  templated_ligurian_news_train_sample     templated  \n",
       "1       Latn  templated_ligurian_news_train_sample     templated  \n",
       "2       Latn  templated_ligurian_news_train_sample     templated  \n",
       "3       Latn  templated_ligurian_news_train_sample     templated  \n",
       "4       Latn  templated_ligurian_news_train_sample     templated  \n",
       "...      ...                                   ...           ...  \n",
       "15071   Latn              aya_dataset_train_sample           aya  \n",
       "15072   Latn              aya_dataset_train_sample           aya  \n",
       "15073   Latn              aya_dataset_train_sample           aya  \n",
       "15074   Latn              aya_dataset_train_sample           aya  \n",
       "15075   Telu              aya_dataset_train_sample           aya  \n",
       "\n",
       "[15076 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a281b91b-53f0-4d81-9573-f75d4b0bcbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15076"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dc3a5cb-6cad-4bf5-b961-860f1ec890ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a Parquet file without the index\n",
    "output_file = \"sampled_aya_all_subsets_15k.parquet\"\n",
    "combined_df.to_parquet(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbf61a-318a-4cce-bf7f-cd485c9d8140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
